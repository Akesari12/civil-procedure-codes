---
title: "Load and tokenize all codes"
author: "Lincoln Mullen"
date: "September 21, 2015"
---

```{r}
library("textreuse")
```

We are going to tokenize the codes and save cached versions. For our initial analysis, we will use skip n-grams with a moderate value for `k` so that we have many features.

```{r}
cache_skip <- "cache/corpus-skip-ngrams-n7k3.rds"
if (!file.exists(cache_skip)) {
  description <- "General purpose tokenization of codes for comparing pairwise."
  corpus_skip <- TextReuseCorpus(dir = "legal-codes/",
                                 meta = list("description" = description,
                                             "title" = "Field codes"),
                                 tokenizer = tokenize_skip_ngrams, n = 7, k = 3,
                                 hash_func = hash_string,
                                 keep_tokens = FALSE)
  dir.create("cache", showWarnings = FALSE)
  corpus_skip
  saveRDS(corpus_skip, file = cache_skip)
}
```

```{r}
cache_shingle <- "cache/corpus-shingle-ngrams-n7.rds"
if (!file.exists(cache_shingle)) {
  description <- "General purpose tokenization of codes for comparing pairwise."
  corpus_shingle <- TextReuseCorpus(dir = "legal-codes/",
                                    meta = list("description" = description,
                                                "title" = "Field codes"),
                                    tokenizer = tokenize_ngrams, n = 7,
                                    hash_func = hash_string,
                                    keep_tokens = FALSE)
  dir.create("cache", showWarnings = FALSE)
  corpus_shingle
  saveRDS(corpus_shingle, file = cache_shingle)
}
```

Session info:

```{r}
sessionInfo()
```

